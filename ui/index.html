<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>voicechat2</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/opus-recorder/8.0.5/recorder.min.js"></script>
    <style>
        body {
            font-family: Arial, sans-serif;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            margin: 0;
            background-color: #f0f0f0;
        }
        .container {
            text-align: center;
            background-color: white;
            padding: 2rem;
            border-radius: 8px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            max-width: 800px;
            width: 100%;
        }
        button {
            font-size: 1rem;
            padding: 0.5rem 1rem;
            margin: 0.5rem;
            cursor: pointer;
        }
        #status, #timer, #latency {
            margin-top: 1rem;
            font-weight: bold;
        }
        #logArea {
            width: 100%;
            height: 400px;
            margin-top: 1rem;
            padding: 0.5rem;
            border: 1px solid #ccc;
            overflow-y: auto;
            text-align: left;
            font-family: monospace;
            font-size: 0.9rem;
        }
        #conversationLog {
            width: 100%;
            height: 300px;
            border: 1px solid #ccc;
            overflow-y: auto;
            margin-top: 1rem;
            padding: 0.5rem;
            font-family: Arial, sans-serif;
        }
        .user-message {
            color: blue;
        }
        .ai-message {
            color: green;
        }
        #latencyMetrics {
            margin-top: 10px;
            font-size: 0.9em;
            font-family: monospace;
        }
        #latencyMetrics table {
            width: 100%;
            border-collapse: collapse;
        }
        #latencyMetrics th, #latencyMetrics td {
            border: 1px solid #ddd;
            padding: 8px;
            text-align: left;
        }
        #latencyMetrics th {
            background-color: #f2f2f2;
            font-weight: bold;
        }
        #recordButton {
            user-select: none;
            -webkit-user-select: none;
            -moz-user-select: none;
            -ms-user-select: none;
        }
        #recordButton:active {
            background-color: #ff0000;
            color: white;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>voicechat2</h1>
        <div id="timer">00:00:000</div>
        <button id="recordButton">Press and Hold to Chat</button>
        <p>You can also hold the space bar to chat!</p>
        <div id="latencyMetrics">
            <table>
                <tr>
                    <th>Metric</th>
                    <th>Value</th>
                </tr>
                <tr>
                    <td>Total Voice-to-Voice</td>
                    <td id="totalVoiceToVoice">0ms</td>
                </tr>
                <tr>
                    <td>SRT Duration</td>
                    <td id="srtDuration">0ms</td>
                </tr>
                <tr>
                    <td>LLM TTFT</td>
                    <td id="llmTTFT">0ms</td>
                </tr>
                <tr>
                    <td>LLM TTFS</td>
                    <td id="llmTTFS">0ms</td>
                </tr>
                <tr>
                    <td>TTS Duration</td>
                    <td id="ttsDuration">0ms</td>
                </tr>
                <tr>
                    <td>Network Latency</td>
                    <td id="networkLatency">0ms</td>
                </tr>
            </table>
        </div>
        <div id="status">Ready</div>
        <div id="conversationLog"></div>
        <div id="logArea"></div>
    </div>

    <script>
        // Elements to update
        const recordButton = document.getElementById('recordButton');
        const status = document.getElementById('status');
        const logArea = document.getElementById('logArea');
        const timerDisplay = document.getElementById('timer');

        // Network
        let startTime;
        let socket;
        let isProcessing = false;
        let latencyIntervalId = null;
        let ping = null;

        // Recording
        let isRecording = false;
        let recordingStartTime;
        let recorder;
        let timerInterval;

        // Text 
        let currentAIResponse = '';
        let aiMessageElement = null;
        let isAIResponding = false;

        // Playback
        let audioQueue = [];
        let isPlaying = false;

        // Ping every second
        function startLatencyMeasurement() {
            if (latencyIntervalId === null) {
                latencyIntervalId = setInterval(measureLatency, 1000);
            }
        }

        function stopLatencyMeasurement() {
            if (latencyIntervalId !== null) {
                clearInterval(latencyIntervalId);
                latencyIntervalId = null;
            }
        }

        function measureLatency() {
            if (!isProcessing) {
                ping = performance.now();
                socket.send(JSON.stringify({ type: 'ping' }));
            }
        }

        function updateLatencyDisplay(latency) {
          const latencyElement = document.getElementById('networkLatency');
          if (latencyElement) {
            latencyElement.textContent = `${latency.toFixed(2)}ms`;
          }
        }

        function startRecording() {
            if (!isRecording) {
                stopLatencyMeasurement();

                // Clear the previous AI response when starting a new recording
                currentAIResponse = '';
                aiMessageElement = null;
                isAIResponding = false;

                isRecording = true;
                recordingStartTime = Date.now();
                updateTimerDisplay();
                recorder.start();
                document.getElementById('status').textContent = 'Recording...';
            }
        }

        function stopRecording() {
            if (isRecording) {
                isRecording = false;
                recorder.stop()
                    .then(() => {
                        document.getElementById('status').textContent = 'Processing...';
                        log('Recording stopped successfully');
                        recordingEndTime = Date.now();
                        // Send stop_recording message to server
                        if (socket && socket.readyState === WebSocket.OPEN) {
                            const stopMessage = JSON.stringify({ action: "stop_recording" });
                            log(`Sending stop_recording message: ${stopMessage}`);
                            socket.send(stopMessage);
                        } else {
                            log(`WebSocket is not open. State: ${socket ? socket.readyState : 'undefined'}`);
                        }
                    })
                    .catch((error) => {
                        log(`Error stopping recording: ${error.message}`);
                    });
            }
        }

        function updateTimerDisplay() {
            if (isRecording) {
                const elapsed = Date.now() - recordingStartTime;
                const minutes = Math.floor(elapsed / 60000);
                const seconds = Math.floor((elapsed % 60000) / 1000);
                const milliseconds = elapsed % 1000;
                timerDisplay.textContent = `${minutes.toString().padStart(2, '0')}:${seconds.toString().padStart(2, '0')}:${milliseconds.toString().padStart(3, '0')}`;
                requestAnimationFrame(updateTimerDisplay);
            }
        }

        // Button event listeners
        recordButton.addEventListener('mousedown', startRecording);
        recordButton.addEventListener('mouseup', stopRecording);
        recordButton.addEventListener('mouseleave', stopRecording);

        // Spacebar event listeners
        document.addEventListener('keydown', (event) => {
            if (event.code === 'Space' && !isRecording) {
                event.preventDefault(); // Prevent scrolling
                startRecording();
            }
        });

        document.addEventListener('keyup', (event) => {
            if (event.code === 'Space') {
                event.preventDefault();
                stopRecording();
            }
        });

        // Touch event listeners for mobile devices
        recordButton.addEventListener('touchstart', (event) => {
            event.preventDefault();
            startRecording();
        });

        recordButton.addEventListener('touchend', (event) => {
            event.preventDefault();
            stopRecording();
        });

        function playNextAudio() {
            if (audioQueue.length === 0 || isPlaying) {
                return;
            }

            isPlaying = true;
            const audioBlob = audioQueue.shift();
            const audio = new Audio(URL.createObjectURL(audioBlob));

            audio.onended = () => {
                isPlaying = false;
                playNextAudio(); // Play the next audio in the queue
            };

            audio.onerror = (error) => {
                log(`Error playing audio: ${error.message}`);
                isPlaying = false;
                playNextAudio(); // Try to play the next audio in case of an error
            };

            audio.play().catch((error) => {
                log(`Error starting audio playback: ${error.message}`);
                isPlaying = false;
                playNextAudio(); // Try to play the next audio in case of an error
            });
        }

        function queueAudioForPlayback(audioBlob) {
            audioQueue.push(audioBlob);
            playNextAudio(); // Try to play if not already playing
        }

        function log(message) {
            const timestamp = new Date().toISOString();
            logArea.innerHTML = `${timestamp} - ${message}<br>` + logArea.innerHTML;
        }

        function updateTimer() {
            const elapsed = Date.now() - startTime;
            const minutes = Math.floor(elapsed / 60000);
            const seconds = Math.floor((elapsed % 60000) / 1000);
            const milliseconds = elapsed % 1000;
            timerDisplay.textContent = `${minutes.toString().padStart(2, '0')}:${seconds.toString().padStart(2, '0')}:${milliseconds.toString().padStart(3, '0')}`;
        }

        let audioContext;


        function initializeRecorder() {
            const config = {
                encoderPath: 'https://cdnjs.cloudflare.com/ajax/libs/opus-recorder/8.0.5/encoderWorker.min.js',
                encoderApplication: 2048,
                encoderFrameSize: 20,
                encoderSampleRate: 48000,
                numberOfChannels: 1,
                streamPages: true,
                originalSampleRateOverride: 48000,
                mediaTrackConstraints: { audio: true },
                bufferLength: 8192 // Increase the buffer size to 8192 samples
            };

            recorder = new Recorder(config);

            recorder.ondataavailable = (typedArray) => {
                log(`Data available: ${typedArray.length} bytes`);
                if (socket && socket.readyState === WebSocket.OPEN) {
                    socket.send(typedArray);
                }
            };

            let audioChunks = [];

            recorder.ondataavailable = (typedArray) => {
                log(`Data available: ${typedArray.length} bytes`);
                audioChunks.push(typedArray);
            };

            recorder.onstart = () => {
                log('Recording started');
                status.textContent = 'Recording...';
                startTime = Date.now();
                timerInterval = setInterval(updateTimer, 10);
            };

            recorder.onstop = () => {
                log('Recording stopped');
                status.textContent = 'Processing...';
                clearInterval(timerInterval);

                const blob = new Blob(audioChunks, { 'type' : 'audio/ogg; codecs=opus' });
                audioChunks = []; // Clear the chunks for the next recording
            
                if (socket && socket.readyState === WebSocket.OPEN) {
                    log(`Sending audio file: ${blob.size} bytes`);
                    socket.send(blob);
                } else {
                    log('WebSocket is not open. Cannot send audio.');
                }
            };
        }

        function initAudioContext() {
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            if (audioContext.state === 'suspended') {
                audioContext.resume();
            }
        }


        function playAudio(audioBlob) {
            const audio = new Audio(URL.createObjectURL(audioBlob));
            audio.play();
        }


    function initializeWebSocket() {
            socket = new WebSocket('ws://localhost:8000/ws');

            socket.onopen = () => {
                log('WebSocket connected');
                status.textContent = 'Ready';
                recordButton.disabled = false;

                startLatencyMeasurement();
            };

            socket.onclose = (event) => {
                log(`WebSocket disconnected. Code: ${event.code}, Reason: ${event.reason}`);
                status.textContent = 'Disconnected';
                recordButton.disabled = true;

                stopLatencyMeasurement();
            };

            socket.onerror = (error) => {
                log(`WebSocket error: ${error.message}`);
                status.textContent = 'Error';
            };

            socket.onmessage = (event) => {
                log(`Received message from server: ${typeof event.data}`);
                if (event.data instanceof Blob) {
                    // Handle audio data
                    queueAudioForPlayback(event.data);
                } else {
                    // Handle JSON messages
                    try {
                        const message = JSON.parse(event.data);

                        // Don't spam logs...
                        if (message.type !== 'pong') {
                            log(`Parsed server message: ${JSON.stringify(message)}`);
                        }

                        if (message.type === 'pong') {
                            const latency = performance.now() - ping;
                            // console.log(`Current network latency: ${latency.toFixed(2)}ms`);
                            updateLatencyDisplay(latency);
                        } else if (message.type === 'text') {
                            // Handle streamed text from LLM
                            updateAIResponse(message.content);
                        } else if (message.type === 'transcription') {
                            // Handle transcribed user input
                            displayMessage('User', message.content);
                            // Reset AI response for new turn
                            currentAIResponse = '';
                            aiMessageElement = null;
                            isAIResponding = true;
                        } else if (message.type === 'first_audio_response') {
                            firstResponseTime = Date.now();
                        } else if (message.type === 'latency_metrics') {
                            updateLatencyMetrics(message.metrics);
                        } else if (message.type === 'processing_complete') {
                            status.textContent = 'Ready';
                            isProcessing = false;
                            startLatencyMeasurement;
                            isAIResponding = false;
                            // Remove the cursor
                            if (aiMessageElement) {
                                const cursor = aiMessageElement.querySelector('.ai-cursor');
                                if (cursor) cursor.remove();
                            }
                        } else if (message.type === 'error') {
                            log(`Error from server: ${message.message}`);
                            status.textContent = 'Error';
                        }
                    } catch (error) {
                        log(`Error parsing server message: ${error.message}`);
                    }
                }
            };
        }


        function updateLatencyMetrics(metrics) {
            document.getElementById("totalVoiceToVoice").textContent = `${(metrics.total_voice_to_voice * 1000).toFixed(1)}ms`;
            document.getElementById("srtDuration").textContent = `${(metrics.srt_duration * 1000).toFixed(1)}ms`;
            document.getElementById("llmTTFT").textContent = `${(metrics.llm_ttft * 1000).toFixed(1)}ms`;
            document.getElementById("llmTTFS").textContent = `${(metrics.llm_ttfs * 1000).toFixed(1)}ms`;
            document.getElementById("ttsDuration").textContent = `${(metrics.tts_duration * 1000).toFixed(1)}ms`;
        }


        function displayMessage(role, content) {
            const conversationLog = document.getElementById('conversationLog');
            const messageElement = document.createElement('p');
            messageElement.className = role.toLowerCase() + '-message';
            messageElement.textContent = `${role}: ${content}`;
            conversationLog.appendChild(messageElement);
            conversationLog.scrollTop = conversationLog.scrollHeight;
            return messageElement;
        }

        function updateAIResponse(newContent) {
            currentAIResponse += newContent;
            if (!aiMessageElement) {
                aiMessageElement = displayMessage('AI', '');
            }
            aiMessageElement.innerHTML = `AI: ${currentAIResponse}${isAIResponding ? '<span class="ai-cursor"></span>' : ''}`;
            const conversationLog = document.getElementById('conversationLog');
            conversationLog.scrollTop = conversationLog.scrollHeight;
        }


        /*
        recordButton.onclick = () => {
            // Initialize AudioContext on first user interaction
            if (!audioContext) {
                initAudioContext();
            }

            if (isRecording) {
                isRecording = false;
                recordButton.textContent = 'Start Recording';
                recorder.stop()
                    .then(() => {
                        log('Recording stopped successfully');
                        recordingEndTime = Date.now();
                        // Send stop_recording message to server
                        if (socket && socket.readyState === WebSocket.OPEN) {
                            const stopMessage = JSON.stringify({ action: "stop_recording" });
                            log(`Sending stop_recording message: ${stopMessage}`);
                            socket.send(stopMessage);
                        } else {
                            log(`WebSocket is not open. State: ${socket ? socket.readyState : 'undefined'}`);
                        }
                    })
                    .catch((error) => {
                        log(`Error stopping recording: ${error.message}`);
                    });
            } else {
                isRecording = true;
                recordButton.textContent = 'Stop Recording';

                // Clear the previous AI response when starting a new recording
                currentAIResponse = '';
                aiMessageElement = null;
                isAIResponding = false;

                recorder.start()
                    .then(() => {
                        log('Recording started successfully');
                    })
                    .catch((error) => {
                        log(`Error starting recording: ${error.message}`);
                    });
            }
        };
        */


        let recordingEndTime;
        let firstResponseTime;
        
        // Initialize recorder and WebSocket when the page loads
        window.onload = () => {
            initializeRecorder();
            initializeWebSocket();
            log('Application initialized');
        };
    </script>
</body>
</html>
